# -*- coding: utf-8 -*-
"""SBA_Data_Capstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EjDJNEDCBGus2JnRXyyHUG1KT3C6rEpv
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import scipy.stats as stats
from sklearn.preprocessing import StandardScaler,RobustScaler
from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,classification_report
import warnings
warnings.filterwarnings('ignore')
plt.rcParams['figure.figsize']=[15,6]

import kagglehub

# Download latest version
path = kagglehub.dataset_download("mirbektoktogaraev/should-this-loan-be-approved-or-denied")

print("Path to dataset files:", path)

df1 = pd.read_csv('/root/.cache/kagglehub/datasets/mirbektoktogaraev/should-this-loan-be-approved-or-denied/versions/2/SBAnational.csv')
df1.head()

"""The dataset includes the information about SBA loans taken from 1962 to 2014 such as name, city, state of the borrower, bank info, business info and loan details. Also, it has a status of the loan: "paid in full" or "charged off". The purpose of this project is to create a model to predict if the loan will be paid in full."""

df1.info()

"""Data Exploration"""

df1.describe().T

df1.describe(include='object').T

"""All monetary columns should be numerical and not objects:DisbursementGross, BalanceGross, ChgOffPrinGr, GrAppv,SBA_Appr. Changing the format to numerical."""

df1['DisbursementGross']=df1['DisbursementGross'].str.replace('$', '')
df1['GrAppv']=df1['GrAppv'].str.replace('$', '')
df1['SBA_Appv']=df1['SBA_Appv'].str.replace('$', '')
df1['BalanceGross']=df1['BalanceGross'].str.replace('$', '')
df1['ChgOffPrinGr']=df1['ChgOffPrinGr'].str.replace('$', '')

df1['DisbursementGross']=df1['DisbursementGross'].str.replace(',', '')
df1['GrAppv']=df1['GrAppv'].str.replace(',', '')
df1['SBA_Appv']=df1['SBA_Appv'].str.replace(',', '')
df1['BalanceGross']=df1['BalanceGross'].str.replace(',', '')
df1['ChgOffPrinGr']=df1['ChgOffPrinGr'].str.replace(',', '')

df1['DisbursementGross']=pd.to_numeric(df1['DisbursementGross'], downcast='float')
df1['BalanceGross']=pd.to_numeric(df1['BalanceGross'], downcast='float')
df1['ChgOffPrinGr']=pd.to_numeric(df1['ChgOffPrinGr'], downcast='float')
df1['GrAppv']=pd.to_numeric(df1['GrAppv'], downcast='float')
df1['SBA_Appv']=pd.to_numeric(df1['SBA_Appv'], downcast='float')

df1=df1.drop('ChgOffDate', axis=1)
# column has over 80% of null values

df1.dropna(inplace=True)

df1.info()

numerical_cols = ['NoEmp', 'CreateJob', 'RetainedJob', 'NewExist', 'Term', 'SBA_Appv', 'GrAppv', 'ChgOffPrinGr', 'BalanceGross', 'DisbursementGross', 'UrbanRural']
categorical_cols = ['MIS_Status', 'LowDoc', 'RevLineCr', 'ApprovalFY', 'State']

df=df1.copy()

# Data visualization

import plotly.express as px
for col in categorical_cols:
  vals = df[col].value_counts()
  fig = px.bar(
        df, x=vals.index, y=vals.values,
        #title = f'{col} distribution',
        text_auto='.2s',
        height=500
    )
  fig.update_xaxes(title_text=col)
  fig.update_yaxes(title_text='Count')
  fig.update_layout(title_x=0.5)
  fig.show()
  # MIS_Status, LowDoc and RevLineCr have few distinct values (less than 18)

import plotly.graph_objects as go
from plotly.subplots import make_subplots
for col in numerical_cols:
    fig = make_subplots(rows=1, cols=2,
                        subplot_titles=(f'Histogram of {col}', f'Boxplot of {col}'))

    fig.add_trace(
        go.Histogram(x=df[col]),
        row=1, col=1
    )

    # Boxplot
    fig.add_trace(
        go.Box(y=df[col]),
        row=1, col=2
    )

    # Update layout
    fig.update_layout(
        width=800, height=400, title_text=f'Distribution and Boxplot of {col}', showlegend=False)

    fig.update_xaxes(title_text= col, row=1, col=1)
    fig.update_xaxes(title_text= col, row=1, col=2)

    fig.show()

    # Term, Noempl, CreatedJobs, RetainedJob have a lot of outliers
    # NewExist - has three distinct values
    #

for col in df1.columns:
  print(f'{col} values are: ')
  print(df1[col].nunique())
  print(df1[col].dtype)
  print(df1[col].unique())
  print('-'*30)
  #UrbanRural, NewExist, RevLineCr, LowDoc have few unique values less than 18

corr_matrix = df1[numerical_cols].corr()
#plt.figure(figsize=(20, 15))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()
#retainedJob and CreateJob are highly correlated. To decrease the number of features the sum of jobs variable will be created.
#SBA_Appv, GrAppv and DisbursementGross are highly correlated. For the first model only SBA_Appv will be used.

df1['jobs']=df1['CreateJob']+df1['RetainedJob']

#eliminating outliers in numerical columns using 90% as values threshold

import scipy.stats as stats
from scipy.stats.mstats import winsorize

df1["win_noemp"] = winsorize(df1["NoEmp"], (0, 0.10))
df1["win_job"] = winsorize(df1["jobs"], (0, 0.10))
df1["win_sbaappv"] = winsorize(df1["SBA_Appv"], (0, 0.10))
df1["win_term"] = winsorize(df1["Term"], (0, 0.10))

df1.info()

df=df1[['State', 'ApprovalFY', 'win_term', 'win_job', 'win_sbaappv', 'win_noemp', 'MIS_Status', 'RevLineCr', 'UrbanRural', 'NewExist', 'LowDoc']]

from sklearn import ensemble
from sklearn.model_selection import cross_val_score
import time
start = time.time()

rfc = ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1)
X = df.drop('MIS_Status', axis=1)
Y = df['MIS_Status']
X = pd.get_dummies(X)

print(f'{cross_val_score(rfc, X, Y, cv=10)}\n')

print(f'Cross-validation time elapsed: {round(time.time() - start, 2)} seconds.')

#the model shows inconsistent result ranging from 31% to 90% of variance being explained by this model

import matplotlib.pyplot as plt

rfc.fit(X, Y)

feat_importances = pd.Series(rfc.feature_importances_, index=X.columns)
feat_importances.nlargest(20).plot(kind='barh')

"""The biggest contributors to the final prediction are win_term, win_sbappv, win-noemp, win-job, urbanrural. Removing State and Approval year to see if results will improve."""

df_test2=df1[['win_term', 'win_job', 'win_sbaappv', 'win_noemp', 'MIS_Status', 'RevLineCr', 'UrbanRural', 'NewExist', 'LowDoc']]

start = time.time()

rfc = ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1)
X = df_test2.drop('MIS_Status', axis=1)
Y = df_test2['MIS_Status']
X = pd.get_dummies(X)

print(f'{cross_val_score(rfc, X, Y, cv=10)}\n')

print(f'Cross-validation time elapsed: {round(time.time() - start, 2)} seconds.')

# Removing both state and year resulted in more consistent results around 90%, also the time required for calculation decreased three times.

import matplotlib.pyplot as plt

rfc.fit(X, Y)

feat_importances = pd.Series(rfc.feature_importances_, index=X.columns)
feat_importances.nlargest(20).plot(kind='barh')

!pip install pydotplus
!conda install -c anaconda graphviz

from sklearn import tree
# A convenience for displaying visualizations
from IPython.display import Image

# Packages for rendering the tree
import pydotplus
import graphviz

# Initialize and train the tree
decision_tree = tree.DecisionTreeClassifier(
    criterion='entropy',
    max_features=1,
    max_depth=4,
    random_state = 1337 ,

)
decision_tree.fit(X, Y)

# Render the tree
dot_data = tree.export_graphviz(
    decision_tree, out_file=None,
    feature_names=X.columns,
    class_names=['Charged Off', 'Paid in Full'],
    filled=True
)
graph = pydotplus.graph_from_dot_data(dot_data)
Image(graph.create_png())

# creating gradient boosting classifier model
# converting categorical to numerical target variable ("0" and "1" values, "1" - paid in full) to be able to use in the model

y = df_test2['MIS_Status']
y=pd.get_dummies(y)
y=y.drop('CHGOFF', axis=1)
y = y.replace({True: 1, False: 0})

# Commented out IPython magic to ensure Python compatibility.
import itertools
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score
# %matplotlib inline

# Defining predictors.

X = df_test2.drop('MIS_Status', axis=1)
X = pd.get_dummies(X)

# Create training and test sets.
offset = int(X.shape[0] * 0.8)

# Put 80% of the data in the training set.
X_train, y_train = X[:offset], y[:offset]

# And put 20% in the test set.
X_test, y_test = X[offset:], y[offset:]

# Making 500 iterations, with 2-deep trees, and loss function "log loss".

# Initialize and fit the model.
params = {'n_estimators': 500,
          'max_depth': 2,
          'loss': 'log_loss'}

# Initialize and fit the model.
clf = ensemble.GradientBoostingClassifier(**params)
clf.fit(X_train, y_train)

predict_train = clf.predict(X_train)
predict_test = clf.predict(X_test)



def plot_confusion_matrix(cm, classes,normalize,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes)
    plt.yticks(tick_marks, classes)
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center", verticalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

#Accuracy:
a=clf.score(X_test, y_test)
#Precision score
y_pred = clf.predict(X_test)
b=precision_score(y_test,y_pred)
#Recall score
c=recall_score(y_test,y_pred)

print('Accuracy score', format(a))
print('Precision score', format(b))
print('Recall score', format(c))


cm = confusion_matrix(y_test, predict_test)
plot_confusion_matrix(cm,[0,1],False)

#changing the loss function to 'exponential' to see if results will improve

params = {'n_estimators': 500,
          'max_depth': 2,
          'loss': 'exponential'}

# Initialize and fit the model.
clf = ensemble.GradientBoostingClassifier(**params)
clf.fit(X_train, y_train)

predict_train = clf.predict(X_train)
predict_test = clf.predict(X_test)

#Accuracy:
a=clf.score(X_test, y_test)
#Precision score
y_pred = clf.predict(X_test)
b=precision_score(y_test,y_pred)
#Recall score
c=recall_score(y_test,y_pred)

print('Accuracy score', format(a))
print('Precision score', format(b))
print('Recall score', format(c))


cm = confusion_matrix(y_test, predict_test)
plot_confusion_matrix(cm,[0,1],False)